services:

  # ─── PostgreSQL ───────────────────────────────────────────────
  db:
    image: supabase/postgres:15.8.1.060
    environment:
      POSTGRES_HOST: /var/run/postgresql
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: postgres
      JWT_SECRET: ${JWT_SECRET}
      POSTGRES_HOST_AUTH_METHOD: md5
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - supabase-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -h localhost"]
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  # ─── Supavisor ────────────────────────────────────────────────
  supavisor:
    image: supabase/supavisor:2.5.1
    ports:
      - "6543:6543"
      - "5433:5433"
    networks:
      - supabase-net
    environment:
      POSTGRES_HOST: db
      POSTGRES_PORT: 5432
      POSTGRES_DB: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DATABASE_URL: "ecto://supabase_admin:${POSTGRES_PASSWORD}@db:5432/postgres"
      CLUSTER_POSTGRES: "true"
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      VAULT_ENC_KEY: ${VAULT_ENC_KEY}
      API_JWT_SECRET: ${JWT_SECRET}
      METRICS_JWT_SECRET: ${JWT_SECRET}
      REGION: local
      ERL_AFLAGS: -proto_dist inet_tcp
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  # ─── pg-meta ──────────────────────────────────────────────────
  meta:
    image: supabase/postgres-meta:v0.84.2
    networks:
      - supabase-net
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: db
      PG_META_DB_PORT: 5432
      PG_META_DB_NAME: postgres
      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  # ─── Kong Init ────────────────────────────────────────────────
  kong-init:
    image: alpine:3.19
    networks:
      - supabase-net
    environment:
      KONG_ADMIN_USER: ${KONG_ADMIN_USER}
      KONG_ADMIN_PASSWORD: ${KONG_ADMIN_PASSWORD}
    volumes:
      - kong-config:/var/lib/kong
    command:
      - sh
      - -c
      - |
        set -e
        echo "Gerando kong.yml..."
        cat > /var/lib/kong/kong.yml << KONGEOF
        _format_version: "1.1"

        consumers:
          - username: $$KONG_ADMIN_USER
            basicauth_credentials:
              - username: $$KONG_ADMIN_USER
                password: $$KONG_ADMIN_PASSWORD

        services:
          - name: pg-meta
            url: http://meta:8080
            routes:
              - name: pg-meta-all
                strip_path: true
                paths:
                  - /pg/

          - name: studio
            url: http://studio:3000
            routes:
              - name: studio-route
                strip_path: false
                paths:
                  - /
                regex_priority: 0
            plugins:
              - name: basic-auth
                config:
                  hide_credentials: true

        plugins:
          - name: cors
            config:
              origins:
                - "*"
              methods:
                - GET
                - POST
                - PUT
                - PATCH
                - DELETE
                - OPTIONS
              headers:
                - Accept
                - Authorization
                - Content-Type
                - apikey
                - X-Client-Info
              max_age: 1728000
              credentials: true
        KONGEOF
        sed -i "s/\$\$KONG_ADMIN_USER/$$KONG_ADMIN_USER/g" /var/lib/kong/kong.yml
        sed -i "s/\$\$KONG_ADMIN_PASSWORD/$$KONG_ADMIN_PASSWORD/g" /var/lib/kong/kong.yml
        echo "kong.yml gerado!"
        cat /var/lib/kong/kong.yml
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        max_attempts: 3
      placement:
        constraints:
          - node.role == manager

  # ─── Kong (API Gateway) ───────────────────────────────────────
  kong:
    image: kong:2.8.1
    ports:
      - "8000:8000"
    networks:
      - supabase-net
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /var/lib/kong/kong.yml
      KONG_DNS_ORDER: A,CNAME,LAST
      KONG_DNS_NOT_FOUND_TTL: 2
      KONG_DNS_ERROR_TTL: 2
      KONG_DNS_RESOLVER: 127.0.0.11
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
    volumes:
      - kong-config:/var/lib/kong
    entrypoint:
      - sh
      - -c
      - |
        echo 'Aguardando kong.yml...';
        until [ -s /var/lib/kong/kong.yml ]; do
          sleep 2;
        done;
        echo 'kong.yml encontrado, iniciando Kong...';
        /docker-entrypoint.sh kong docker-start
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 10
      placement:
        constraints:
          - node.role == manager

  # ─── Supabase Studio ──────────────────────────────────────────
  studio:
    image: supabase/studio:20250113-83c9420
    networks:
      - supabase-net
    environment:
      STUDIO_PG_META_URL: http://meta:8080
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION:-Minha Empresa}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT:-Meu Projeto}
      SUPABASE_URL: http://kong:8000
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL:-http://localhost:8000}
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

networks:
  supabase-net:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.10.0/24

volumes:
  db-data:
    driver: local
  kong-config:
    driver: local